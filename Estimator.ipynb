{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Parameters\n",
    "conv_dropout = 0.4\n",
    "dense_dropout = 0.5\n",
    "l2_regularization = 0.001\n",
    "\n",
    "# l1_regularizer = tf.keras.regularizers.l1(0.01)\n",
    "l2_regularizer = None #tf.keras.regularizers.l2(l2_regularization)\n",
    "\n",
    "CROP_UP = 50\n",
    "CROP_DOWN = 30\n",
    "final_height = 160 - (CROP_UP + CROP_DOWN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aux functions for batchnorm layers\n",
    "def conv2d_batch_norm(*args, **kwargs):\n",
    "\n",
    "    activation = kwargs.pop(\"activation\", None)\n",
    "    batch_norm = kwargs.pop(\"batch_norm\", {})\n",
    "\n",
    "    net = tf.layers.conv2d(*args, **kwargs)\n",
    "    net = tf.layers.batch_normalization(net, **batch_norm)\n",
    "\n",
    "    return activation(net) if activation else net\n",
    "\n",
    "def dense_batch_norm(*args, **kwargs):\n",
    "\n",
    "    activation = kwargs.pop(\"activation\", None)\n",
    "    batch_norm = kwargs.pop(\"batch_norm\", {})\n",
    "\n",
    "    net = tf.layers.dense(*args, **kwargs)\n",
    "    net = tf.layers.batch_normalization(net, **batch_norm)\n",
    "\n",
    "    return activation(net) if activation else net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0\n",
    "sigma = 0.1\n",
    "init = None #tf.initializers.truncated_normal(mean = mu, stddev = sigma)\n",
    "\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features, [-1, final_height, 320, 3])\n",
    "\n",
    "    general_ops = dict(\n",
    "#         activation = activation,\n",
    "        batch_norm = dict(training = mode == tf.estimator.ModeKeys.TRAIN)\n",
    "#         kernel_regularizer = tf.contrib.layers.l2_regularizer(l2_regularization),\n",
    "    )\n",
    "                                             \n",
    "    input_normalized = tf.layers.batch_normalization(input_layer, training = mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # Convolutional Layer #1\n",
    "    conv1 = conv2d_batch_norm(\n",
    "      inputs=input_normalized,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"valid\",\n",
    "      activation=tf.nn.relu, kernel_initializer=init,\n",
    "      **general_ops)\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    pool1 = tf.layers.dropout(\n",
    "        inputs=pool1, \n",
    "        rate=conv_dropout, \n",
    "        training= mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = conv2d_batch_norm(\n",
    "      inputs=pool1,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"valid\",\n",
    "      activation=tf.nn.relu, kernel_initializer=init,\n",
    "    **general_ops)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    pool2 = tf.layers.dropout(\n",
    "        inputs=pool2, \n",
    "        rate=conv_dropout, \n",
    "        training= mode == tf.estimator.ModeKeys.TRAIN)\n",
    "                                             \n",
    "    # Convolutional Layer #3 and Pooling Layer #3\n",
    "    conv3 = conv2d_batch_norm(\n",
    "      inputs=pool2,\n",
    "      filters=64,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"valid\",\n",
    "      activation=tf.nn.relu, kernel_initializer=init,\n",
    "    **general_ops)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "    pool3 = tf.layers.dropout(\n",
    "        inputs=pool3, \n",
    "        rate=conv_dropout, \n",
    "        training= mode == tf.estimator.ModeKeys.TRAIN)  \n",
    "                                             \n",
    "    # Convolutional Layer #4 and Pooling Layer #4\n",
    "    conv4 = conv2d_batch_norm(\n",
    "      inputs=pool3,\n",
    "      filters=64,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"valid\",\n",
    "      activation=tf.nn.relu, kernel_initializer=init,\n",
    "    **general_ops)\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
    "    pool4 = tf.layers.dropout(\n",
    "        inputs=pool4, \n",
    "        rate=conv_dropout, \n",
    "        training= mode == tf.estimator.ModeKeys.TRAIN)  \n",
    "                                             \n",
    "    # Dense Layers\n",
    "    pool_flat = tf.layers.flatten(conv4)\n",
    "    \n",
    "    dense1 = dense_batch_norm(inputs=pool_flat,\n",
    "                             units=1024,\n",
    "                             activation=tf.nn.relu,\n",
    "                             kernel_initializer=init,\n",
    "                             **general_ops)\n",
    "    dense1 = tf.layers.dropout(\n",
    "        inputs=dense1, \n",
    "        rate=dense_dropout, \n",
    "        training= mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    dense2 = dense_batch_norm(inputs=dense1,\n",
    "                             units=512,\n",
    "                             activation=tf.nn.relu,\n",
    "                             kernel_initializer=init,\n",
    "                             **general_ops)\n",
    "    dense2 = tf.layers.dropout(\n",
    "        inputs=dense2, \n",
    "        rate=dense_dropout, \n",
    "        training= mode == tf.estimator.ModeKeys.TRAIN)\n",
    "                                             \n",
    "    dense3 = dense_batch_norm(inputs=dense2,\n",
    "                             units=128,\n",
    "                             activation=tf.nn.relu,\n",
    "                             kernel_initializer=init,\n",
    "                             **general_ops)\n",
    "    dense3 = tf.layers.dropout(\n",
    "        inputs=dense3, \n",
    "        rate=dense_dropout, \n",
    "        training= mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    preds = tf.layers.dense(inputs=dense3, units=1, kernel_initializer=init)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"steering\": preds\n",
    "    }\n",
    "\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    with tf.name_scope('loss'):\n",
    "            loss = tf.losses.mean_squared_error(\n",
    "                labels=labels, predictions=tf.squeeze(preds, axis = 1), scope='loss')\n",
    "            tf.summary.scalar('loss', loss)\n",
    "    \n",
    "    # Accuracy    \n",
    "    with tf.name_scope('mae'):\n",
    "            mae = tf.metrics.mean_absolute_error(\n",
    "                labels=labels, predictions=tf.squeeze(preds, axis = 1), name='mae')\n",
    "            tf.summary.scalar('mae', mae[1])\n",
    "\n",
    "    # Create a hook to print acc, loss & global step every 100 iter.   \n",
    "    train_hook_list= []\n",
    "    train_tensors_log = {'mae': mae[1],\n",
    "                         'loss': loss}\n",
    "    train_hook_list.append(tf.train.LoggingTensorHook(\n",
    "        tensors=train_tensors_log, every_n_iter=100))\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "#             optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "#             optimizer = tf.train.AdagradOptimizer(learning_rate=0.001)\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode=mode, \n",
    "                loss=loss, \n",
    "                train_op=train_op, \n",
    "                training_hooks=train_hook_list)\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops={'mae/mae': mae}, evaluation_hooks=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_device_fn': None, '_protocol': None, '_save_checkpoints_steps': None, '_model_dir': '/tmp/pilotnetV1', '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_eval_distribute': None, '_tf_random_seed': None, '_service': None, '_task_id': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_global_id_in_cluster': 0, '_train_distribute': None, '_num_ps_replicas': 0, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f31d2644668>, '_save_checkpoints_secs': 600, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_experimental_distribute': None, '_master': '', '_evaluation_master': '', '_is_chief': True}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"/tmp/pilotnetV1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "### folder where the data is\n",
    "DATASET = \"data_mine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>break</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>/home/charlie/data/charlie/self-driving-nano/C...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              center  \\\n",
       "0  /home/charlie/data/charlie/self-driving-nano/C...   \n",
       "1  /home/charlie/data/charlie/self-driving-nano/C...   \n",
       "2  /home/charlie/data/charlie/self-driving-nano/C...   \n",
       "3  /home/charlie/data/charlie/self-driving-nano/C...   \n",
       "4  /home/charlie/data/charlie/self-driving-nano/C...   \n",
       "\n",
       "                                                left  \\\n",
       "0  /home/charlie/data/charlie/self-driving-nano/C...   \n",
       "1  /home/charlie/data/charlie/self-driving-nano/C...   \n",
       "2  /home/charlie/data/charlie/self-driving-nano/C...   \n",
       "3  /home/charlie/data/charlie/self-driving-nano/C...   \n",
       "4  /home/charlie/data/charlie/self-driving-nano/C...   \n",
       "\n",
       "                                               right  steering  throttle  \\\n",
       "0  /home/charlie/data/charlie/self-driving-nano/C...       0.0       0.0   \n",
       "1  /home/charlie/data/charlie/self-driving-nano/C...       0.0       0.0   \n",
       "2  /home/charlie/data/charlie/self-driving-nano/C...       0.0       0.0   \n",
       "3  /home/charlie/data/charlie/self-driving-nano/C...       0.0       0.0   \n",
       "4  /home/charlie/data/charlie/self-driving-nano/C...       0.0       0.0   \n",
       "\n",
       "   break     speed  \n",
       "0      0  0.000020  \n",
       "1      0  0.000011  \n",
       "2      0  0.000011  \n",
       "3      0  0.000021  \n",
       "4      0  0.000016  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load csv as a pandas dataframe\n",
    "header = [\"center\", \"left\", \"right\", \"steering\", \"throttle\", \"break\", \"speed\"]\n",
    "df = pd.read_csv(os.path.join(DATASET, \"driving_log.csv\"), header=None, names=header)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(filename):\n",
    "    return os.path.join(DATASET,\"IMG\", filename.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>break</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_mine/IMG/center_2019_02_03_21_24_02_332.jpg</td>\n",
       "      <td>data_mine/IMG/left_2019_02_03_21_24_02_332.jpg</td>\n",
       "      <td>data_mine/IMG/right_2019_02_03_21_24_02_332.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_mine/IMG/center_2019_02_03_21_24_02_398.jpg</td>\n",
       "      <td>data_mine/IMG/left_2019_02_03_21_24_02_398.jpg</td>\n",
       "      <td>data_mine/IMG/right_2019_02_03_21_24_02_398.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_mine/IMG/center_2019_02_03_21_24_02_467.jpg</td>\n",
       "      <td>data_mine/IMG/left_2019_02_03_21_24_02_467.jpg</td>\n",
       "      <td>data_mine/IMG/right_2019_02_03_21_24_02_467.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_mine/IMG/center_2019_02_03_21_24_02_536.jpg</td>\n",
       "      <td>data_mine/IMG/left_2019_02_03_21_24_02_536.jpg</td>\n",
       "      <td>data_mine/IMG/right_2019_02_03_21_24_02_536.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_mine/IMG/center_2019_02_03_21_24_02_605.jpg</td>\n",
       "      <td>data_mine/IMG/left_2019_02_03_21_24_02_605.jpg</td>\n",
       "      <td>data_mine/IMG/right_2019_02_03_21_24_02_605.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             center  \\\n",
       "0  data_mine/IMG/center_2019_02_03_21_24_02_332.jpg   \n",
       "1  data_mine/IMG/center_2019_02_03_21_24_02_398.jpg   \n",
       "2  data_mine/IMG/center_2019_02_03_21_24_02_467.jpg   \n",
       "3  data_mine/IMG/center_2019_02_03_21_24_02_536.jpg   \n",
       "4  data_mine/IMG/center_2019_02_03_21_24_02_605.jpg   \n",
       "\n",
       "                                             left  \\\n",
       "0  data_mine/IMG/left_2019_02_03_21_24_02_332.jpg   \n",
       "1  data_mine/IMG/left_2019_02_03_21_24_02_398.jpg   \n",
       "2  data_mine/IMG/left_2019_02_03_21_24_02_467.jpg   \n",
       "3  data_mine/IMG/left_2019_02_03_21_24_02_536.jpg   \n",
       "4  data_mine/IMG/left_2019_02_03_21_24_02_605.jpg   \n",
       "\n",
       "                                             right  steering  throttle  break  \\\n",
       "0  data_mine/IMG/right_2019_02_03_21_24_02_332.jpg       0.0       0.0      0   \n",
       "1  data_mine/IMG/right_2019_02_03_21_24_02_398.jpg       0.0       0.0      0   \n",
       "2  data_mine/IMG/right_2019_02_03_21_24_02_467.jpg       0.0       0.0      0   \n",
       "3  data_mine/IMG/right_2019_02_03_21_24_02_536.jpg       0.0       0.0      0   \n",
       "4  data_mine/IMG/right_2019_02_03_21_24_02_605.jpg       0.0       0.0      0   \n",
       "\n",
       "      speed  \n",
       "0  0.000020  \n",
       "1  0.000011  \n",
       "2  0.000011  \n",
       "3  0.000021  \n",
       "4  0.000016  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Make paths relative to this jupyter notebook\n",
    "df[\"center\"] = df.center.apply(get_image_path)\n",
    "df[\"left\"] = df.left.apply(get_image_path)\n",
    "df[\"right\"] = df.right.apply(get_image_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split train and dev set \n",
    "train_samples, validation_samples = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filenames and labels (steerings)\n",
    "c_filenames = train_samples.center.values\n",
    "c_labels = train_samples.steering.values\n",
    "\n",
    "val_filenames = validation_samples.center.values\n",
    "val_labels = validation_samples.steering.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add side cameras to train set\n",
    "steer_correction = 0.2\n",
    "\n",
    "l_filenames = train_samples.left.values\n",
    "l_labels = train_samples.steering.values + steer_correction\n",
    "\n",
    "r_filenames = train_samples.right.values\n",
    "r_labels = train_samples.steering.values - steer_correction\n",
    "\n",
    "filenames = np.concatenate([c_filenames, l_filenames, r_filenames])\n",
    "labels = np.concatenate([c_labels, l_labels, r_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aux function to crop the images\n",
    "def get_crop_window(crop_up, crop_down):\n",
    "    final_height = 160 - (crop_up + crop_down)\n",
    "    final_width = 320\n",
    "\n",
    "    return [\n",
    "        crop_up,\n",
    "        0,\n",
    "        final_height,\n",
    "        final_width,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the image decoded from jpg and label\n",
    "\n",
    "def parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "\n",
    "    # Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    \n",
    "    image = tf.image.decode_and_crop_jpeg(\n",
    "            image_string,\n",
    "            crop_window = get_crop_window(CROP_UP, CROP_DOWN),\n",
    "            channels = 3\n",
    "        )\n",
    "\n",
    "    # This will convert to float values in [0, 1]\n",
    "#     image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "#     image = tf.image.resize_images(image, [160, 320])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of TF DataSet API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "steps_per_epoch = len(train_samples)*3//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "def create_train_dataset():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.shuffle(len(filenames))\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=4)\n",
    "    dataset = dataset.repeat(EPOCHS)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dev dataset\n",
    "def create_eval_dataset():\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_filenames, val_labels))\n",
    "    val_dataset = val_dataset.map(parse_function, num_parallel_calls=4)\n",
    "    val_dataset = val_dataset.repeat(EPOCHS)\n",
    "    val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "    val_dataset = val_dataset.prefetch(1)\n",
    "    return val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get image example for trainig\n",
    "# sess = tf.Session()\n",
    "# value = dataset.make_one_shot_iterator().get_next()\n",
    "# x,y = sess.run(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x.shape, y[0])\n",
    "# plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specs\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=create_train_dataset,\n",
    "    max_steps=EPOCHS*steps_per_epoch)\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=create_eval_dataset,\n",
    "    steps=None,\n",
    "    start_delay_secs=10,  # Start evaluating after 10 sec.\n",
    "    throttle_secs=30  # Evaluate only every 30 sec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/pilotnetV1/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.615762, step = 0\n",
      "INFO:tensorflow:loss = 1.615762, mae = 1.0200002\n",
      "INFO:tensorflow:global_step/sec: 2.75243\n",
      "INFO:tensorflow:loss = 0.4548871, step = 100 (36.332 sec)\n",
      "INFO:tensorflow:loss = 0.4548871, mae = 0.7770497 (36.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78025\n",
      "INFO:tensorflow:loss = 0.32424098, step = 200 (35.969 sec)\n",
      "INFO:tensorflow:loss = 0.32424098, mae = 0.6513096 (35.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79265\n",
      "INFO:tensorflow:loss = 0.31865963, step = 300 (35.807 sec)\n",
      "INFO:tensorflow:loss = 0.31865963, mae = 0.5737839 (35.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80135\n",
      "INFO:tensorflow:loss = 0.12611216, step = 400 (35.698 sec)\n",
      "INFO:tensorflow:loss = 0.12611216, mae = 0.50957906 (35.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85133\n",
      "INFO:tensorflow:loss = 0.06852467, step = 500 (35.071 sec)\n",
      "INFO:tensorflow:loss = 0.06852467, mae = 0.45709208 (35.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88943\n",
      "INFO:tensorflow:loss = 0.056643855, step = 600 (34.608 sec)\n",
      "INFO:tensorflow:loss = 0.056643855, mae = 0.4185361 (34.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88023\n",
      "INFO:tensorflow:loss = 0.051202275, step = 700 (34.720 sec)\n",
      "INFO:tensorflow:loss = 0.051202275, mae = 0.3899213 (34.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81852\n",
      "INFO:tensorflow:loss = 0.03683394, step = 800 (35.480 sec)\n",
      "INFO:tensorflow:loss = 0.03683394, mae = 0.3631171 (35.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85467\n",
      "INFO:tensorflow:loss = 0.030236604, step = 900 (35.031 sec)\n",
      "INFO:tensorflow:loss = 0.030236604, mae = 0.34037164 (35.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86569\n",
      "INFO:tensorflow:loss = 0.02586111, step = 1000 (34.897 sec)\n",
      "INFO:tensorflow:loss = 0.02586111, mae = 0.32194185 (34.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86413\n",
      "INFO:tensorflow:loss = 0.038557924, step = 1100 (34.913 sec)\n",
      "INFO:tensorflow:loss = 0.038557924, mae = 0.30895272 (34.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.80425\n",
      "INFO:tensorflow:loss = 0.018420108, step = 1200 (35.662 sec)\n",
      "INFO:tensorflow:loss = 0.018420108, mae = 0.29325286 (35.664 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1230 into /tmp/pilotnetV1/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-02-11-04:10:24\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/pilotnetV1/model.ckpt-1230\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-02-11-04:10:36\n",
      "INFO:tensorflow:Saving dict for global step 1230: global_step = 1230, loss = 0.0077712745, mae/mae = 0.067136265\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1230: /tmp/pilotnetV1/model.ckpt-1230\n",
      "INFO:tensorflow:Loss for final step: 0.02635322.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'global_step': 1230, 'loss': 0.0077712745, 'mae/mae': 0.067136265}, [])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "### Save the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
